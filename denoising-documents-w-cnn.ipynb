{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"code","source":"import numpy as np \nimport scipy as sp \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport glob \nimport cv2\nimport sklearn\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nimport seaborn as sns\nimport tensorflow as tf\n\ntrain_imgs = glob.glob(\"../input/train/*.png\")\ntrain_imgs.sort()\ntrain_cleaned_imgs = glob.glob(\"../input/train_cleaned/*.png\")\ntrain_cleaned_imgs.sort()\ntest_imgs= glob.glob(\"../input/test/*.png\")","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"collapsed":true},"cell_type":"code","source":"PATCH_WIDTH_HALF = 4\nPATCH_WIDTH = PATCH_WIDTH_HALF * 2 + 1\n\ndef train_patch_generator(train_imgs, train_cleaned_imgs, epochs = 5):\n    for _ in range(epochs):\n        for train_file, train_cleaned_file in zip(train_imgs, train_cleaned_imgs):\n            patches = []\n            labels = []\n            train_img = cv2.imread(train_file, cv2.IMREAD_GRAYSCALE)\n            train_cleaned_img = cv2.imread(train_cleaned_file, cv2.IMREAD_GRAYSCALE)\n            train_cleaned_img = cv2.threshold(train_cleaned_img, 200, 255,cv2.THRESH_BINARY)[1]\n            train_img_ext = cv2.copyMakeBorder(train_img, PATCH_WIDTH_HALF, PATCH_WIDTH_HALF, PATCH_WIDTH_HALF, PATCH_WIDTH_HALF, cv2.BORDER_REPLICATE)\n            #thresholded_img_ext = cv2.adaptiveThreshold(train_img_ext,255,cv2.ADAPTIVE_THRESH_MEAN_C,\n            #                                            cv2.THRESH_BINARY,51,30)\n            #eroded_img_ext = cv2.erode(train_img_ext, np.ones((3,3),np.uint8), 1)\n            #eroded_thresh_ext = cv2.erode(thresholded_img_ext, np.ones((3,3),np.uint8), 1)\n            for i in range(train_img.shape[0]):\n                for j in range(train_img.shape[1]):\n                    label = train_cleaned_img[i][j]\n                    patch_c1 = train_img_ext[i:i+PATCH_WIDTH, j:j+PATCH_WIDTH].astype(np.float32)/255.\n                    #patch_c2 = thresholded_img_ext[i:i+PATCH_WIDTH, j:j+PATCH_WIDTH].astype(np.float32)/255.\n                    #patch_c3 = eroded_img_ext[i:i+PATCH_WIDTH, j:j+PATCH_WIDTH].astype(np.float32)/255.\n                    #patch_c4 = eroded_thresh_ext[i:i+PATCH_WIDTH, j:j+PATCH_WIDTH].astype(np.float32)/255.\n                    patches.append(np.expand_dims(patch_c1, axis=2))\n                    #patches.append(np.stack((patch_c1, patch_c2), axis=2))\n                    labels.append(label / 255.)\n            patches = np.array(patches)# patches.shape\n            labels = np.array(labels) # labels.shape\n            yield (patches, labels)\n            ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ff08cdae11a7248ab280d7aec5b125b69072a319","collapsed":true},"cell_type":"code","source":"model = tf.keras.models.Sequential()\nmodel.add(tf.keras.layers.Conv2D(32, kernel_size=(3, 3), strides=(1, 1), padding='same',\n          activation='relu', input_shape=(PATCH_WIDTH, PATCH_WIDTH, 1)))\nmodel.add(tf.keras.layers.Flatten())\nmodel.add(tf.keras.layers.Dense(512, activation='relu'))\nmodel.add(tf.keras.layers.Dense(256, activation='relu'))\nmodel.add(tf.keras.layers.Dropout(rate=0.5))\nmodel.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n\nmodel.compile(loss=tf.keras.losses.binary_crossentropy,\n              optimizer=tf.keras.optimizers.Adam(lr=0.002),\n              metrics=['mse'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7d6cf3fc7d9f977c16d883abc32b8f1599d076ea","collapsed":true},"cell_type":"code","source":"partial_train_imgs, validate_imgs, partial_train_labels, validate_labels = train_test_split(train_imgs, train_cleaned_imgs, test_size=0.1)\n# len(partial_train_imgs)\n# len(validate_imgs)\nEPOCHS=10\nmodel.fit_generator(train_patch_generator(partial_train_imgs, partial_train_labels, EPOCHS), epochs=EPOCHS, steps_per_epoch=len(partial_train_labels))\nscore = model.evaluate_generator(train_patch_generator(validate_imgs, validate_labels, 1), steps=len(validate_labels))\nprint(score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e7411329c28f09a1ca06598dca5d51e103529f2e","collapsed":true},"cell_type":"code","source":"def test_patch_generator(test_imgs):\n    for test_file in test_imgs:\n        patches = []\n        test_img = cv2.imread(test_file, cv2.IMREAD_GRAYSCALE)\n        test_img_ext = cv2.copyMakeBorder(test_img, PATCH_WIDTH_HALF, PATCH_WIDTH_HALF, PATCH_WIDTH_HALF, PATCH_WIDTH_HALF, cv2.BORDER_REPLICATE)\n        #thresholded_img_ext = cv2.adaptiveThreshold(test_img_ext,255,cv2.ADAPTIVE_THRESH_MEAN_C,\n        #                                            cv2.THRESH_BINARY,51,30) \n        #eroded_img_ext = cv2.erode(train_img_ext, np.ones((3,3),np.uint8), 1)\n        #eroded_thresh_ext = cv2.erode(thresholded_img_ext, np.ones((3,3),np.uint8), 1)\n        for i in range(test_img.shape[0]):\n            for j in range(test_img.shape[1]):\n                patch_c1 = test_img_ext[i:i+PATCH_WIDTH, j:j+PATCH_WIDTH].astype(np.float32) / 255.\n                #patch_c2 = thresholded_img_ext[i:i+PATCH_WIDTH, j:j+PATCH_WIDTH].astype(np.float32)/255.\n                #patch_c3 = eroded_img_ext[i:i+PATCH_WIDTH, j:j+PATCH_WIDTH].astype(np.float32)/255..\n                #patch_c4 = eroded_thresh_ext[i:i+PATCH_WIDTH, j:j+PATCH_WIDTH].astype(np.float32)/255..\n                patches.append(np.expand_dims(patch_c1, axis=2))\n                #patches.append(np.stack((patch_c1, patch_c2), axis=2))\n        patches = np.array(patches)\n        yield patches\n\ndef test_patch_id_generator(test_imgs):\n    for test_file in test_imgs:\n        id = test_file.replace('../input/test/', '').replace('.png', '')\n        pids = []\n        test_img = cv2.imread(test_file, cv2.IMREAD_GRAYSCALE)\n        for i in range(test_img.shape[0]):\n            for j in range(test_img.shape[1]):\n                pids.append(id + '_' + str(i+1) + '_' + str(j+1)) \n        yield pids","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5618336a1c981746aa907a10e1c0678e74992b13","scrolled":false,"collapsed":true},"cell_type":"code","source":"for idx in [8]:\n    img = cv2.imread(train_imgs[idx], cv2.IMREAD_GRAYSCALE)\n    cleaned_img = cv2.imread(train_cleaned_imgs[idx], cv2.IMREAD_GRAYSCALE)\n    predicted_mask = model.predict_generator(\n        generator=test_patch_generator([train_imgs[idx]]),\n        steps=1).reshape(img.shape).clip(0, 1).round()\n    predicted = cv2.bitwise_and(img, 255, mask=(1-predicted_mask).astype(np.uint8))\n    predicted = cv2.bitwise_or(predicted, 255, mask=predicted_mask.astype(np.uint8))\n    plt.figure(figsize=(60,30))\n    plt.subplot(2,2,1)\n    plt.imshow(img, 'gray');\n    plt.title('Uncleaned')\n    plt.subplot(2,2,2)\n    plt.imshow(cleaned_img, 'gray');\n    plt.title('Manually Cleaned')\n    plt.subplot(2,2,3)\n    plt.imshow(predicted, 'gray');\n    plt.title('Auto Cleaned')\n    plt.subplot(2,2,4)\n    plt.imshow(cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY,51,30), 'gray');\n    plt.title('Adaptive Threshold Cleaned')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f044e00b41fa36d1c7d0df5f7793e11dc7e76f14","collapsed":true},"cell_type":"code","source":"for i, f in enumerate(test_imgs):\n    img = cv2.imread(f, cv2.IMREAD_GRAYSCALE)\n    predicted = model.predict_generator(\n        generator=test_patch_generator([f]),\n        steps=1).clip(0, 1)\n    df = pd.DataFrame({'id': [], 'value': []})\n    df['id'] = next(test_patch_id_generator([f]))\n    df['value'] = predicted\n    if i == 0:\n        df.to_csv('submission.csv', header=True, index=False)\n    else:\n        df.to_csv('submission.csv', header=False, mode='a', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}