{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import keras\nfrom keras.models import Model\nfrom keras.optimizers import Adadelta\nfrom keras.callbacks import EarlyStopping\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import load_img, array_to_img, img_to_array\nfrom keras.optimizers import Adam\nfrom keras.layers import Input, Dense, Activation, BatchNormalization, Flatten, Conv2D\nfrom keras.layers import MaxPooling2D, Dropout, UpSampling2D\nimport glob\nfrom keras.callbacks import ModelCheckpoint","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TRAIN_IMAGES = sorted(glob.glob('/kaggle/input/noise_doc/noise_doc/*.png'))\nCLEAN_IMAGES = sorted(glob.glob('/kaggle/input/original_doc/original_doc/*.png'))\nprint(\"Total number of images in the training set: \", len(TRAIN_IMAGES))\nprint(\"Total number of cleaned images found: \", len(CLEAN_IMAGES))","execution_count":7,"outputs":[{"output_type":"stream","text":"Total number of images in the training set:  144\nTotal number of cleaned images found:  144\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets' define our autoencoder now\ndef build_autoenocder():\n    input_img = Input(shape=(420,540,1), name='image_input')    \n    #enoder \n    x = Conv2D(32, (3,3), activation='relu', padding='same', name='Conv1')(input_img)\n    x = MaxPooling2D((2,2), padding='same', name='pool1')(x)   \n    #decoder\n    x = Conv2D(32, (3,3), activation='relu', padding='same', name='Conv2')(x)\n    x = UpSampling2D((2,2), name='upsample3')(x)\n    x = Conv2D(1, (3,3), activation='sigmoid', padding='same', name='Conv3')(x)   \n    #model\n    autoencoder = Model(inputs=input_img, outputs=x)\n    autoencoder.compile(optimizer='Adam', loss='binary_crossentropy')\n    return autoencoder\n\nautoencoder = build_autoenocder()\nautoencoder.summary()","execution_count":8,"outputs":[{"output_type":"stream","text":"Model: \"model_2\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nimage_input (InputLayer)     (None, 420, 540, 1)       0         \n_________________________________________________________________\nConv1 (Conv2D)               (None, 420, 540, 32)      320       \n_________________________________________________________________\npool1 (MaxPooling2D)         (None, 210, 270, 32)      0         \n_________________________________________________________________\nConv2 (Conv2D)               (None, 210, 270, 32)      9248      \n_________________________________________________________________\nupsample3 (UpSampling2D)     (None, 420, 540, 32)      0         \n_________________________________________________________________\nConv3 (Conv2D)               (None, 420, 540, 1)       289       \n=================================================================\nTotal params: 9,857\nTrainable params: 9,857\nNon-trainable params: 0\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = []\nY = []\n\ntrain_images = TRAIN_IMAGES\ntrain_labels = CLEAN_IMAGES\n\nfor img in train_images:\n    img = load_img(img, grayscale=True,target_size=(420,540))\n    img = img_to_array(img).astype('float32')/255.\n    X.append(img)\n\nfor img in train_labels:\n    img = load_img(img, grayscale=True,target_size=(420,540))\n    img = img_to_array(img).astype('float32')/255.\n    Y.append(img)\n\n\nX = np.array(X)\nY = np.array(Y)\n\nprint(\"Size of X : \", X.shape)\nprint(\"Size of Y : \", Y.shape)","execution_count":9,"outputs":[{"output_type":"stream","text":"Size of X :  (144, 420, 540, 1)\nSize of Y :  (144, 420, 540, 1)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"autoencoder = build_autoenocder()\nautoencoder.summary()\n\n# checkpoint\nfilepath=\"weights-improvement-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n#checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1)#, save_best_only=True, mode='max')\ncheckpoint = ModelCheckpoint(\"best_model.hdf5\", monitor='val_acc', verbose=1,save_best_only=True, mode='auto', period=1)\n#callbacks_list = [checkpoint]","execution_count":18,"outputs":[{"output_type":"stream","text":"Model: \"model_7\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nimage_input (InputLayer)     (None, 420, 540, 1)       0         \n_________________________________________________________________\nConv1 (Conv2D)               (None, 420, 540, 32)      320       \n_________________________________________________________________\npool1 (MaxPooling2D)         (None, 210, 270, 32)      0         \n_________________________________________________________________\nConv2 (Conv2D)               (None, 210, 270, 32)      9248      \n_________________________________________________________________\nupsample3 (UpSampling2D)     (None, 420, 540, 32)      0         \n_________________________________________________________________\nConv3 (Conv2D)               (None, 420, 540, 1)       289       \n=================================================================\nTotal params: 9,857\nTrainable params: 9,857\nNon-trainable params: 0\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train your model\nautoencoder.fit(X, Y, epochs=2, batch_size=16, callbacks=[checkpoint])","execution_count":19,"outputs":[{"output_type":"stream","text":"Epoch 1/2\n144/144 [==============================] - 1s 6ms/step - loss: 0.5640\n\nEpoch 00001: loss improved from inf to 0.56404, saving model to best_model.hdf5\nEpoch 2/2\n144/144 [==============================] - 1s 5ms/step - loss: 0.3489\n\nEpoch 00002: loss improved from 0.56404 to 0.34895, saving model to best_model.hdf5\n","name":"stdout"},{"output_type":"execute_result","execution_count":19,"data":{"text/plain":"<keras.callbacks.callbacks.History at 0x7efc1c0b32b0>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get the predition\nsample_test = load_img(train_images[100], grayscale=True, target_size=(420,540))\nsample_test = img_to_array(sample_test)\nsample_test_img = sample_test.astype('float32')/255.\nsample_test_img = np.expand_dims(sample_test, axis=0)\n\n# Get the predition\npredicted_label = np.squeeze(autoencoder.predict(sample_test_img))\n\nf, ax = plt.subplots(1,2, figsize=(10,8))\nax[0].imshow(np.squeeze(sample_test), cmap='gray')\nax[1].imshow(np.squeeze(predicted_label.astype('int8')), cmap='gray')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}